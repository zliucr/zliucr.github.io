---
title: "Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual Task-oriented Dialogue Systems"
collection: publications
permalink: /publication/2019-06-15-paper-generalizing
excerpt: ''
date: 2019-11-23
venue: 'AAAI-2020'
paperurl: 'https://arxiv.org/pdf/1911.09273.pdf'
authors: 'Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng Xu, Pascale Fung'
citation: 'Liu, Z., Winata, G. I., Lin, Z., Xu, P., & Fung, P. (2019). Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual Task-oriented Dialogue Systems. arXiv preprint arXiv:1907.12108.'
---
Recently, data-driven task-oriented dialogue systems have achieved promising performance in English. However, developing dialogue systems that support low-resource languages remains a long-standing challenge due to the absence of high-quality data. In order to circumvent the expensive and time-consuming data collection, we introduce Attention-Informed Mixed-Language Training (MLT), a novel zero-shot adaptation method for cross-lingual task-oriented dialogue systems. It leverages very few task-related parallel word pairs to generate code-switching sentences for learning the inter-lingual semantics across languages. Instead of manually selecting the word pairs, we propose to extract source words based on the scores computed by the attention layer of a trained English task-related model and then generate word pairs using existing bilingual dictionaries. Furthermore, intensive experiments with different cross-lingual embeddings demonstrate the effectiveness of our approach. Finally, with very few word pairs, our model achieves significant zero-shot adaptation performance improvements in both cross-lingual dialogue state tracking and natural language understanding (i.e., intent detection and slot filling) tasks compared to the current state-of-the-art approaches, which utilize a much larger amount of bilingual data.

[Paper](https://arxiv.org/pdf/1911.09273.pdf)

Recommended citation: Liu, Z., Winata, G. I., Lin, Z., Xu, P., & Fung, P. (2019). Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual Task-oriented Dialogue Systems. arXiv preprint arXiv:1907.12108.